# 常见问题 FAQ

## 1. 模型输出不稳定怎么办？

- 调整 `temperature` 或 `top_p`，降低随机性。
- 提示词中增加约束与示例，减少模型发挥空间。
- 使用高阶模型（如 GPT-4 系列）提升一致性。

## 2. 如何保证事实准确？

- 在提示词中要求引用来源或在无法确认时回答“未知”。
- 结合检索、知识库或函数调用，实现检索增强生成（RAG）。
- 引入人工审核流程，对关键信息进行复核。

## 3. 如何节省成本？

- 选择更轻量的模型（如 `gpt-4o-mini`）。
- 控制上下文长度，裁剪历史对话或使用摘要。
- 对重复请求实施缓存策略，减少重复调用。

## 4. 中文效果不佳？

- 尽量使用中文提示词，并提供示例输出格式。
- 若涉及专业术语，可同时提供中文解释与英文原文。
- 对于较长内容，可分段处理并在最后汇总。

## 5. 如何处理敏感内容？

- 明确告知模型不可生成的内容类型。
- 使用 OpenAI Moderation API 检测用户输入与模型输出。
- 建立人工复核机制，定期审计对话记录。

## 6. 调试提示词的技巧？

- 逐条修改、对比不同版本的效果，记录实验结果。
- 使用思维链（Chain-of-Thought）引导模型分步推理。
- 将复杂任务拆分为多个子任务，逐一处理。

更多问题欢迎在 Issue 中讨论或提交 PR 补充。
